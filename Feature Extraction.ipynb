{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Text_representations.ipynb","provenance":[],"collapsed_sections":["wbXMz2crpv7m","dYdXcpa7Yf7V","-hpkRE0frtKw","52-rMNKCrrfX","mJC_DOnEuqhE","7s9zLvtD0lVl","I3wh1XzW0HGi","OIgQ2cNDsXux","1H_00C7F64yE","NdjQ0RsuKrLa","sbwVOX9VSTel","jSjiROhrdRnK","ucnA7aiA49-G","CSXYZ4MmOs2H"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"rPk1zPTZhCcl","colab_type":"text"},"source":["## Feature Extraction Techniques\n","\n","Machine Learning or Deep learning algorithams can not accept text directly . Some numerical representation is required so that these algorithm can process the data .In simple machine learning algorithms we use\n","    \n","  #### Count vectorizer \n","\n","  #### TF-IDF vectorizer .\n","\n","Both of which do not preserve any relation between the words . There comes the word embedding which map all the words in a language to a vector space . word2vec is a popular method to generate word Embedding . How does word2vec do the task of generating vectors from the words .There are two algorithms for that\n","\n","   #### Coninuous Bag Of Words  - Predicting target word from context words\n","    \n","   #### Skip Gram - Predicting context words from Target word  \n"]},{"cell_type":"markdown","metadata":{"id":"wbXMz2crpv7m","colab_type":"text"},"source":["# One hot encoding\n"]},{"cell_type":"code","metadata":{"id":"dlFdPiZ2qAVV","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import OneHotEncoder\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cfy-RT7JqBZ7","colab_type":"code","colab":{}},"source":["data=[['b'],['a'],['c']]\n","#data should be a list of a list"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9-D2wNJ8qBfR","colab_type":"code","outputId":"77885e86-8278-4dcc-99bb-b319c11fb9c4","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1580831788892,"user_tz":-330,"elapsed":1823,"user":{"displayName":"Shobana Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCv7Hfykf1w3ZXZuUHkxNexIa7rZMUIuglNEWBbEQ=s64","userId":"10883314765117040201"}}},"source":["enc = OneHotEncoder(handle_unknown='ignore')\n","enc.fit(data)\n","x=enc.transform(data).toarray()\n","print(x)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[[0. 1. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dYdXcpa7Yf7V","colab_type":"text"},"source":["# Term Document Matrix (TDM)\n"]},{"cell_type":"code","metadata":{"id":"kjU10EHbYaXo","colab_type":"code","colab":{}},"source":["corpus = ['This is the first document.','This document is the second document.','And this is the third one.', 'Is this the first document?']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YZv3qhhCYj4J","colab_type":"code","outputId":"e608eeb4-cb59-48a2-e072-7265c39d2632","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1580831788894,"user_tz":-330,"elapsed":1813,"user":{"displayName":"Shobana Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCv7Hfykf1w3ZXZuUHkxNexIa7rZMUIuglNEWBbEQ=s64","userId":"10883314765117040201"}}},"source":["print(corpus)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["['This is the first document.', 'This document is the second document.', 'And this is the third one.', 'Is this the first document?']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NEshSr-pamrl","colab_type":"text"},"source":["### Count Vectorization\n","\n","This method turns each vector into sparse matrix. It will make sure the word present in the vocabulary and if present it prints the number of occurrences of the word in vocabulary .Consider a Corpus C of D documents {d1,d2…..dD} and N unique tokens extracted out of the corpus C. The N tokens will form our dictionary and the size of the Count Vector matrix M will be given by D X N. Each row in the matrix M contains the frequency of tokens in document D(i).\n","\n"]},{"cell_type":"code","metadata":{"id":"DfR1vlw3YyMD","colab_type":"code","colab":{}},"source":["from sklearn.feature_extraction.text import CountVectorizer\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hihH912gYo3w","colab_type":"code","outputId":"931cd851-d36e-40dd-9684-e024ae418455","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1580831788895,"user_tz":-330,"elapsed":1802,"user":{"displayName":"Shobana Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCv7Hfykf1w3ZXZuUHkxNexIa7rZMUIuglNEWBbEQ=s64","userId":"10883314765117040201"}}},"source":["vectorizer = CountVectorizer()\n","X = vectorizer.fit_transform(corpus).toarray()\n","print(X)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[[0 1 1 1 0 0 1 0 1]\n"," [0 2 0 1 0 1 1 0 1]\n"," [1 0 0 1 1 0 1 1 1]\n"," [0 1 1 1 0 0 1 0 1]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JQv0m3ftY1fL","colab_type":"code","outputId":"fa77d497-a0e0-4938-e1a6-cc71f9c9f984","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1580831788896,"user_tz":-330,"elapsed":1795,"user":{"displayName":"Shobana Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCv7Hfykf1w3ZXZuUHkxNexIa7rZMUIuglNEWBbEQ=s64","userId":"10883314765117040201"}}},"source":["vocabulary = vectorizer.get_feature_names()\n","print(vocabulary)\n","print(len(vocabulary))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n","9\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"52-rMNKCrrfX","colab_type":"text"},"source":["## Character - level"]},{"cell_type":"code","metadata":{"id":"ti2dZ5S_q_II","colab_type":"code","outputId":"9b29298d-8407-4458-e46b-0a4294fc4b23","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1580831788896,"user_tz":-330,"elapsed":1787,"user":{"displayName":"Shobana Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCv7Hfykf1w3ZXZuUHkxNexIa7rZMUIuglNEWBbEQ=s64","userId":"10883314765117040201"}}},"source":["vectorizer = CountVectorizer(analyzer = 'char')\n","X = vectorizer.fit_transform(corpus).toarray()\n","print(X)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[[4 1 0 0 1 1 2 1 2 3 1 1 1 1 3 4 1]\n"," [5 1 0 0 3 3 4 0 2 2 2 3 3 0 3 4 2]\n"," [5 1 0 1 0 2 2 0 3 3 0 2 1 1 2 3 0]\n"," [4 0 1 0 1 1 2 1 2 3 1 1 1 1 3 4 1]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NNBatNkxr-KT","colab_type":"code","outputId":"1c203f6b-90f9-42b9-888f-71c524421b22","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1580831788897,"user_tz":-330,"elapsed":1780,"user":{"displayName":"Shobana Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCv7Hfykf1w3ZXZuUHkxNexIa7rZMUIuglNEWBbEQ=s64","userId":"10883314765117040201"}}},"source":["vocabulary = vectorizer.get_feature_names()\n","print(vocabulary)\n","print(len(vocabulary))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[' ', '.', '?', 'a', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u']\n","17\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OIgQ2cNDsXux","colab_type":"text"},"source":["#  TF - IDF\n","\n","\n","In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling. The tf–idf value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word, which helps to adjust for the fact that some words appear more frequently in general. tf–idf is one of the most popular term-weighting schemes today; 83% of text-based recommender systems in digital libraries use tf–idf.\n","\n","\n","#### Term Frequency (TF) = (Number of times term t appears in a document)/(Number of terms in the document)\n","\n","#### Inverse Document Frequency (IDF) = log(N/n),\n","\n","where, N is the number of documents and n is the number of documents a term t has appeared in. \n","\n","The IDF of a rare word is high, whereas the IDF of a frequent word is likely to be low. Thus having the effect of highlighting words that are distinct.\n","\n","#### TF-IDF  = TF * IDF\n","\n","\n","Consider a document containing 100 words wherein the word cat appears 3 times. The term frequency (i.e., tf) for cat is then (3 / 100) = 0.03. Now, assume we have 10 million documents and the word cat appears in one thousand of these. Then, the inverse document frequency (i.e., idf) is calculated as log(10,000,000 / 1,000) = 4. Thus, the Tf-idf weight is the product of these quantities: 0.03 * 4 = 0.12.\n"]},{"cell_type":"code","metadata":{"id":"8-BkO7QksFDu","colab_type":"code","colab":{}},"source":["from sklearn.feature_extraction.text import TfidfVectorizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1S0hTC8csDFR","colab_type":"code","outputId":"4b176105-b97f-4d72-832f-2c2bc62fe5e7","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1580831788898,"user_tz":-330,"elapsed":1769,"user":{"displayName":"Shobana Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCv7Hfykf1w3ZXZuUHkxNexIa7rZMUIuglNEWBbEQ=s64","userId":"10883314765117040201"}}},"source":["print(corpus)\n","vectorizer = TfidfVectorizer()\n","X = vectorizer.fit_transform(corpus).toarray()\n","print(X)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["['This is the first document.', 'This document is the second document.', 'And this is the third one.', 'Is this the first document?']\n","[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n","  0.38408524 0.         0.38408524]\n"," [0.         0.6876236  0.         0.28108867 0.         0.53864762\n","  0.28108867 0.         0.28108867]\n"," [0.51184851 0.         0.         0.26710379 0.51184851 0.\n","  0.26710379 0.51184851 0.26710379]\n"," [0.         0.46979139 0.58028582 0.38408524 0.         0.\n","  0.38408524 0.         0.38408524]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lwJnub3VsmlS","colab_type":"code","outputId":"49bf130a-13b7-4240-8232-00763e62aa2a","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1580831788899,"user_tz":-330,"elapsed":1762,"user":{"displayName":"Shobana Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCv7Hfykf1w3ZXZuUHkxNexIa7rZMUIuglNEWBbEQ=s64","userId":"10883314765117040201"}}},"source":["print(vectorizer.get_feature_names())"],"execution_count":13,"outputs":[{"output_type":"stream","text":["['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"92Y-zi4j9QBZ","colab_type":"text"},"source":["#HashingVectorizer"]},{"cell_type":"code","metadata":{"id":"s8zB490-9Oxd","colab_type":"code","outputId":"17c398e0-871c-42ab-d213-fc1273d8d7ef","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1580831788900,"user_tz":-330,"elapsed":1752,"user":{"displayName":"Shobana Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCv7Hfykf1w3ZXZuUHkxNexIa7rZMUIuglNEWBbEQ=s64","userId":"10883314765117040201"}}},"source":["from sklearn.feature_extraction.text import HashingVectorizer\n","corpus = [\n"," 'This is the first document',\n","'This document is the second document',\n","'And this is the third one'\n","\n"," ]\n","vectorizer = HashingVectorizer(n_features=2**4)\n","X = vectorizer.fit_transform(corpus)\n","print(X)\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["  (0, 0)\t-0.5773502691896258\n","  (0, 8)\t-0.5773502691896258\n","  (0, 13)\t0.5773502691896258\n","  (0, 14)\t0.0\n","  (1, 0)\t-0.8164965809277261\n","  (1, 11)\t0.4082482904638631\n","  (1, 13)\t0.4082482904638631\n","  (1, 14)\t0.0\n","  (2, 4)\t-0.7071067811865475\n","  (2, 5)\t0.7071067811865475\n","  (2, 13)\t0.0\n","  (2, 14)\t0.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7s9zLvtD0lVl","colab_type":"text"},"source":[" # N-gram"]},{"cell_type":"code","metadata":{"id":"0oATt-Nt0tuS","colab_type":"code","outputId":"76e2943a-435d-4dec-b70b-33a029426434","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1580831788900,"user_tz":-330,"elapsed":1738,"user":{"displayName":"Shobana Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCv7Hfykf1w3ZXZuUHkxNexIa7rZMUIuglNEWBbEQ=s64","userId":"10883314765117040201"}}},"source":["vectorizer = CountVectorizer(ngram_range = (1,2))\n","X = vectorizer.fit_transform(corpus).toarray()\n","print(X)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["[[0 0 1 0 1 1 1 1 0 0 0 1 1 0 0 0 0 1 0 1]\n"," [0 0 2 1 0 0 1 1 0 1 1 1 0 1 0 0 0 1 1 0]\n"," [1 1 0 0 0 0 1 1 1 0 0 1 0 0 1 1 1 1 0 1]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t_lsahhtzjsG","colab_type":"code","outputId":"7dc6341d-20ed-43b6-e30d-3da29059dc2f","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1580831788901,"user_tz":-330,"elapsed":1729,"user":{"displayName":"Shobana Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCv7Hfykf1w3ZXZuUHkxNexIa7rZMUIuglNEWBbEQ=s64","userId":"10883314765117040201"}}},"source":["vocabulary = vectorizer.get_feature_names()\n","print(vocabulary)\n","print(len(vocabulary))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["['and', 'and this', 'document', 'document is', 'first', 'first document', 'is', 'is the', 'one', 'second', 'second document', 'the', 'the first', 'the second', 'the third', 'third', 'third one', 'this', 'this document', 'this is']\n","20\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"I3wh1XzW0HGi","colab_type":"text"},"source":["## char-level"]},{"cell_type":"code","metadata":{"id":"MtaKT0PG0MKU","colab_type":"code","outputId":"42c23d59-3c7d-4862-d755-08df537ed7c7","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1580831788902,"user_tz":-330,"elapsed":1719,"user":{"displayName":"Shobana Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCv7Hfykf1w3ZXZuUHkxNexIa7rZMUIuglNEWBbEQ=s64","userId":"10883314765117040201"}}},"source":["vectorizer = CountVectorizer(ngram_range = (1,2), analyzer = 'char')\n","X = vectorizer.fit_transform(corpus).toarray()\n","print(X)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["[[4 1 1 1 0 0 1 0 0 1 0 1 1 0 1 2 1 0 1 1 1 2 1 1 3 1 2 1 1 1 0 0 1 1 1 0\n","  1 0 1 3 2 0 1 4 1 2 1 1]\n"," [5 2 0 1 0 1 1 0 0 3 1 2 3 1 2 4 1 1 2 0 0 2 1 1 2 0 2 2 2 3 1 0 2 3 2 1\n","  0 0 0 3 2 1 0 4 1 2 2 2]\n"," [5 0 0 1 1 0 3 1 1 0 0 0 2 2 0 2 1 0 0 0 0 3 1 2 3 1 2 0 0 2 1 1 0 1 0 1\n","  1 1 0 2 2 0 0 3 0 3 0 0]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jU2jOxLM0MRA","colab_type":"code","outputId":"e43749c4-8c3c-4b8c-e25d-1d07a3c2715a","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1580831788903,"user_tz":-330,"elapsed":1710,"user":{"displayName":"Shobana Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCv7Hfykf1w3ZXZuUHkxNexIa7rZMUIuglNEWBbEQ=s64","userId":"10883314765117040201"}}},"source":["vocabulary = vectorizer.get_feature_names()\n","print(vocabulary)\n","print(len(vocabulary))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["[' ', ' d', ' f', ' i', ' o', ' s', ' t', 'a', 'an', 'c', 'co', 'cu', 'd', 'd ', 'do', 'e', 'e ', 'ec', 'en', 'f', 'fi', 'h', 'he', 'hi', 'i', 'ir', 'is', 'm', 'me', 'n', 'nd', 'ne', 'nt', 'o', 'oc', 'on', 'r', 'rd', 'rs', 's', 's ', 'se', 'st', 't', 't ', 'th', 'u', 'um']\n","48\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Y6DcljHV0MVU","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ucnA7aiA49-G","colab_type":"text"},"source":["# word2vec"]},{"cell_type":"code","metadata":{"id":"p7dmez7bssDh","colab_type":"code","colab":{}},"source":["from gensim.models import Word2Vec\n","from nltk.tokenize import word_tokenize"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SH-JpYSq5bB_","colab_type":"code","colab":{}},"source":["data = 'This is the first document. This is the second second document. And the third one. Is this the first document?'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mUwYnRIC5fNP","colab_type":"code","outputId":"256378b8-1334-4cce-d1e7-3a0ddb7d914c","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1580831790666,"user_tz":-330,"elapsed":3454,"user":{"displayName":"Shobana Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCv7Hfykf1w3ZXZuUHkxNexIa7rZMUIuglNEWBbEQ=s64","userId":"10883314765117040201"}}},"source":["import nltk\n","nltk.download('punkt')\n","tokenized_data = []\n","for d in data:\n","    tokenized_data.append(word_tokenize(data))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lBezewD4Nl6M","colab_type":"code","colab":{}},"source":["model = Word2Vec(tokenized_data, size=4, window=2, min_count=1, workers=4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tae_nDYQNq7k","colab_type":"code","outputId":"bb4cc339-241c-4b88-998a-d6df07d9b2c2","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"ok","timestamp":1580831790668,"user_tz":-330,"elapsed":3444,"user":{"displayName":"Shobana Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCv7Hfykf1w3ZXZuUHkxNexIa7rZMUIuglNEWBbEQ=s64","userId":"10883314765117040201"}}},"source":["model.wv.vocab"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'.': <gensim.models.keyedvectors.Vocab at 0x7fbdf9c8f080>,\n"," '?': <gensim.models.keyedvectors.Vocab at 0x7fbdf9c8f208>,\n"," 'And': <gensim.models.keyedvectors.Vocab at 0x7fbdf9c8f0f0>,\n"," 'Is': <gensim.models.keyedvectors.Vocab at 0x7fbdf9c8f198>,\n"," 'This': <gensim.models.keyedvectors.Vocab at 0x7fbdfa247ba8>,\n"," 'document': <gensim.models.keyedvectors.Vocab at 0x7fbdf9c8f048>,\n"," 'first': <gensim.models.keyedvectors.Vocab at 0x7fbdf9c89fd0>,\n"," 'is': <gensim.models.keyedvectors.Vocab at 0x7fbe23511748>,\n"," 'one': <gensim.models.keyedvectors.Vocab at 0x7fbdf9c8f160>,\n"," 'second': <gensim.models.keyedvectors.Vocab at 0x7fbdf9c8f0b8>,\n"," 'the': <gensim.models.keyedvectors.Vocab at 0x7fbe23519c50>,\n"," 'third': <gensim.models.keyedvectors.Vocab at 0x7fbdf9c8f128>,\n"," 'this': <gensim.models.keyedvectors.Vocab at 0x7fbdf9c8f1d0>}"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"o5rIqoDkN6NO","colab_type":"code","outputId":"a24fc845-608c-479c-bc38-902a931148a7","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1580831790669,"user_tz":-330,"elapsed":3437,"user":{"displayName":"Shobana Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCv7Hfykf1w3ZXZuUHkxNexIa7rZMUIuglNEWBbEQ=s64","userId":"10883314765117040201"}}},"source":["model.wv[\"This\"]"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.49980205,  0.47275713, -0.5296022 , -0.5578837 ], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"D-2AXrnYN4gV","colab_type":"code","outputId":"9a56fce7-49c5-49bd-e566-a465b2f3e430","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1580831790670,"user_tz":-330,"elapsed":3430,"user":{"displayName":"Shobana Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCv7Hfykf1w3ZXZuUHkxNexIa7rZMUIuglNEWBbEQ=s64","userId":"10883314765117040201"}}},"source":["model.wv[\"this\"]\n","#model.infer_vector([\"this is\"])"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.4636538 ,  0.33860797, -0.49178052, -0.3085135 ], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"plUVT8GnN88Y","colab_type":"code","outputId":"d228f749-278a-4d2f-bbae-d8ec1ef06885","colab":{"base_uri":"https://localhost:8080/","height":306},"executionInfo":{"status":"error","timestamp":1580831791283,"user_tz":-330,"elapsed":4034,"user":{"displayName":"Shobana Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCv7Hfykf1w3ZXZuUHkxNexIa7rZMUIuglNEWBbEQ=s64","userId":"10883314765117040201"}}},"source":["model.wv[\"Th\"]"],"execution_count":26,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-ef318e2bf15c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Th\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"word 'Th' not in vocabulary\""]}]},{"cell_type":"markdown","metadata":{"id":"CSXYZ4MmOs2H","colab_type":"text"},"source":["# Fasttext"]},{"cell_type":"code","metadata":{"id":"VwlRfwneOvvD","colab_type":"code","colab":{}},"source":["from gensim.models import FastText"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oHMMdMBzOwAH","colab_type":"code","colab":{}},"source":["model = FastText(size=4, window=3, min_count=1) \n","model.build_vocab(sentences=tokenized_data)\n","model.train(sentences=tokenized_data, total_examples=len(tokenized_data), epochs=10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uhKaVIzgOwC0","colab_type":"code","outputId":"b9f19780-62e0-4afc-9317-203151af9e9a","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1580831823537,"user_tz":-330,"elapsed":639,"user":{"displayName":"Shobana Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCv7Hfykf1w3ZXZuUHkxNexIa7rZMUIuglNEWBbEQ=s64","userId":"10883314765117040201"}}},"source":["model.wv[\"This\"]"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.09336837,  1.106698  , -0.9921883 ,  0.3000509 ], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"cCbCcGqAPBSw","colab_type":"code","colab":{}},"source":["model.wv[\"This is\"]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VO8uioFlPFug","colab_type":"code","outputId":"2493a2c4-dc1d-4ea0-e3e8-e39069bc07e6","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1580831829248,"user_tz":-330,"elapsed":1104,"user":{"displayName":"Shobana Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCv7Hfykf1w3ZXZuUHkxNexIa7rZMUIuglNEWBbEQ=s64","userId":"10883314765117040201"}}},"source":["model.wv[\"Th\"]"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.1979229 ,  0.7348152 , -0.7987169 ,  0.00813393], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"7JUAiuYU7mrW","colab_type":"text"},"source":["# Doc2vec"]},{"cell_type":"code","metadata":{"id":"hPMqKe3hCw_q","colab_type":"code","outputId":"5a69602d-5f85-40bc-ade2-c0d340be3bc4","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1580831808278,"user_tz":-330,"elapsed":1202,"user":{"displayName":"Shobana Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCv7Hfykf1w3ZXZuUHkxNexIa7rZMUIuglNEWBbEQ=s64","userId":"10883314765117040201"}}},"source":["\n","from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","from nltk.tokenize import word_tokenize\n","import nltk\n","nltk.download('punkt')"],"execution_count":27,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"HF9NZU7bErTe","colab_type":"code","colab":{}},"source":["data = ['This is the first document.',' This is the second second document.','And the third one.',' Is this the first document?']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LCX3QCMDDIkI","colab_type":"code","colab":{}},"source":["corpus = []\n","for i in range(len(data)):\n","    corpus.append(word_tokenize(data[i]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LbdBgbpeDLTF","colab_type":"code","outputId":"fda70b4b-4e9b-4f4b-fc56-c01a5beab0a0","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1580831837307,"user_tz":-330,"elapsed":976,"user":{"displayName":"Shobana Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCv7Hfykf1w3ZXZuUHkxNexIa7rZMUIuglNEWBbEQ=s64","userId":"10883314765117040201"}}},"source":["corpus"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['This', 'is', 'the', 'first', 'document', '.'],\n"," ['This', 'is', 'the', 'second', 'second', 'document', '.'],\n"," ['And', 'the', 'third', 'one', '.'],\n"," ['Is', 'this', 'the', 'first', 'document', '?']]"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"lCGm4uf_7pdq","colab_type":"code","outputId":"731b4136-286b-46b5-f02c-79a578f7a67e","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1580831841115,"user_tz":-330,"elapsed":976,"user":{"displayName":"Shobana Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCv7Hfykf1w3ZXZuUHkxNexIa7rZMUIuglNEWBbEQ=s64","userId":"10883314765117040201"}}},"source":["documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(corpus)]\n","print(documents)\n","model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["[TaggedDocument(words=['This', 'is', 'the', 'first', 'document', '.'], tags=[0]), TaggedDocument(words=['This', 'is', 'the', 'second', 'second', 'document', '.'], tags=[1]), TaggedDocument(words=['And', 'the', 'third', 'one', '.'], tags=[2]), TaggedDocument(words=['Is', 'this', 'the', 'first', 'document', '?'], tags=[3])]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"USM2CP2tNGLW","colab_type":"code","outputId":"873ba764-70f9-4c20-99f8-ca0fc64f7bc2","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1580831844080,"user_tz":-330,"elapsed":1227,"user":{"displayName":"Shobana Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCv7Hfykf1w3ZXZuUHkxNexIa7rZMUIuglNEWBbEQ=s64","userId":"10883314765117040201"}}},"source":["model.infer_vector([\"this is\"])"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.01125106, -0.01463556, -0.03001213, -0.06343024,  0.08935433],\n","      dtype=float32)"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"3pp8uX6ONN02","colab_type":"code","outputId":"b64e3687-c76f-4ae9-c910-188d5bab6dd8","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1580831846228,"user_tz":-330,"elapsed":1203,"user":{"displayName":"Shobana Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCv7Hfykf1w3ZXZuUHkxNexIa7rZMUIuglNEWBbEQ=s64","userId":"10883314765117040201"}}},"source":["model.infer_vector([\"this\"])"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.05751273, 0.03048443, 0.07658187, 0.02349369, 0.0926259 ],\n","      dtype=float32)"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"JpG-gktmNQDN","colab_type":"code","colab":{}},"source":["model.wv.vocab"],"execution_count":0,"outputs":[]}]}